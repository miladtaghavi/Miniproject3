{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HMM\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"./data/shakespeare.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Split by poems\n",
    "poems = data.split(\"\\n\\n\\n\") \n",
    "# Split poem by line, remove 1st line\n",
    "poems = [poem.split(\"\\n\")[1:] for poem in poems] \n",
    "# Remove the 2 anomalous poems\n",
    "del poems[98]\n",
    "del poems[124]\n",
    "\n",
    "# Remove trailing/leading spaces for certain lines (last 2 lines)\n",
    "poems = [[line.strip() for line in poem] for poem in poems] \n",
    "# Split each line into a list of words\n",
    "poems = [[line.split(\" \") for line in poem] for poem in poems] \n",
    "# Strip punctuation : Optional\n",
    "poems_by_lines = [[[word.strip(\",.:;?!()\").lower() for word in line] for line in poem ] for poem in poems] \n",
    "# Combine all the lines in a single poem so that each pome is just a list of words\n",
    "poems_by_words = [list(itertools.chain.from_iterable(poem)) for poem in poems_by_lines] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Processing and Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary of words. We associate each word with a unique index\n",
    "# and the inverse dictionary associates the index with the word\n",
    "\n",
    "with open(\"./data/Syllable_dictionary.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "lines = [word.strip() for word in data]\n",
    "\n",
    "words_list = []\n",
    "syllables_list = []\n",
    "end_syllables_list = []\n",
    "\n",
    "for line in lines:\n",
    "    word_syllables_list = []\n",
    "    word_end_syllables_list = []\n",
    "    \n",
    "    # Split into the word itself and everything else\n",
    "    word = line.split(\" \")[0]\n",
    "    syllables = line.split(\" \")[1:]\n",
    "    # Iterate over everything else\n",
    "    for syllable in syllables:\n",
    "        # Check that it does not represent an end syllable\n",
    "        if syllable[0] != \"E\":\n",
    "            # Add it to the list syllable count for the current word\n",
    "            word_syllables_list.append(int(syllable))\n",
    "        else:\n",
    "            # Slice off the \"E\" and directly append to the curent word's end_syllables_list\n",
    "            word_end_syllables_list.append(int(syllable[1:]))\n",
    "            \n",
    "    words_list.append(word)\n",
    "    syllables_list.append(tuple(word_syllables_list))\n",
    "    end_syllables_list.append(tuple(word_end_syllables_list))\n",
    "    \n",
    "words_dict = dict(zip(words_list, range(len(words_list))))\n",
    "inverse_words_dict = dict(zip(range(len(words_list)), words_list))\n",
    "syllables_dict = dict(zip(words_list, syllables_list))\n",
    "end_syllables_dict = dict(zip(words_list, end_syllables_list))\n",
    "\n",
    "# Convert each word into an index by searching in the dictionary\n",
    "# We need the function because sometimes there are words that have ' at the start (as part of the word itself)\n",
    "# but sometimes it's just used as a normal quotation mark. So we need to split into 2 cases.\n",
    "def word_idx(word):\n",
    "    try:\n",
    "        return words_dict[word.lower()]\n",
    "    except KeyError:\n",
    "        return words_dict[word.lower().strip(\",.:;?!()'\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire the possible chains of last words as well as rhyming pairs\n",
    "\n",
    "last_words = set()\n",
    "last_word_chains = []\n",
    "rhyme_pairs = defaultdict(set)\n",
    "\n",
    "for poem in poems_by_lines:\n",
    "    # String the last words of the key lines into a list\n",
    "    last_word_chains.append([poem[i][-1] for i in (0, 1, 4, 5, 8, 9, 12)])\n",
    "    \n",
    "    # Register the appropriate pairs of words as rhyming\n",
    "    for i in (0, 1, 4, 5, 8, 9):\n",
    "        rhyme_pairs[poem[i][-1]].add(poem[i+2][-1])\n",
    "        rhyme_pairs[poem[i+2][-1]].add(poem[i][-1])\n",
    "    # Register the last 2 lines' last words\n",
    "    rhyme_pairs[poem[12][-1]].add(poem[13][-1])\n",
    "    rhyme_pairs[poem[13][-1]].add(poem[12][-1])\n",
    "    \n",
    "    # Simply collect all the possible last words \n",
    "    for idx, line in enumerate(poem):\n",
    "        last_words.add(line[-1])\n",
    "        \n",
    "# Convert the list of list of words for each poem's key lines' last words into indices for learning\n",
    "last_word_chains_idx = [[word_idx(word) for word in line] for line in last_word_chains]\n",
    "\n",
    "# TODO: Merge the possible rhymes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all poems together, yielding a list of all lines. We then reverse them and convert to indices.\n",
    "all_lines = list(itertools.chain.from_iterable(poems_by_lines)) \n",
    "all_lines_reversed = [line[::-1] for line in all_lines]\n",
    "all_lines_reversed_idx = [[word_idx(word) for word in line] for line in all_lines_reversed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n"
     ]
    }
   ],
   "source": [
    "# Learn a HMM to generate the last words of each key line in a poem\n",
    "# TODO: vary number of states, iters.\n",
    "last_word_chain_HMM = HMM.unsupervised_HMM(last_word_chains_idx, n_states=10, n_words=len(words_list), N_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n"
     ]
    }
   ],
   "source": [
    "# Train a HMM to construct lines backwards\n",
    "reversed_line_HMM = HMM.unsupervised_HMM(all_lines_reversed_idx, n_states=10, n_words=len(words_list), N_iters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graces art departest call spite lie stand\n",
      "faces depart convertest fall might i hand\n",
      "---\n",
      "graces\n",
      "art\n",
      "faces\n",
      "depart\n",
      "departest\n",
      "call\n",
      "convertest\n",
      "fall\n",
      "spite\n",
      "lie\n",
      "might\n",
      "i\n",
      "stand\n",
      "hand\n"
     ]
    }
   ],
   "source": [
    "# Generate the seeds using the last words HMM and then get the coupling rhymes. These will act as seeds for the \n",
    "# second HMM which generates the line backwards\n",
    "\n",
    "# Emit 7 words from this HMM that learned the last word chains\n",
    "# Take the 0th component because the 1st component shows the hidden state\n",
    "last_words_emission_idx = last_word_chain_HMM.generate_emission(7)[0]\n",
    "last_words_emission = [inverse_words_dict[idx] for idx in last_words_emission_idx]\n",
    "print(\" \".join(last_words_emission))\n",
    "\n",
    "# Use the rhyme dictionary to get the corresponding rhyme words\n",
    "rhymed_words_emission = [random.choice(list(rhyme_pairs[word])) for word in last_words_emission]\n",
    "rhymed_words_emission_idx = [words_dict[word] for word in rhymed_words_emission]\n",
    "print(\" \".join(rhymed_words_emission))\n",
    "\n",
    "\n",
    "# Join all them together in the appropriate alternating fashion\n",
    "last_words_seeds_idx = []\n",
    "for i in range(3):\n",
    "    last_words_seeds_idx.extend([last_words_emission_idx[2*i], last_words_emission_idx[2*i+1]])\n",
    "    last_words_seeds_idx.extend([rhymed_words_emission_idx[2*i], rhymed_words_emission_idx[2*i+1]])\n",
    "last_words_seeds_idx.extend([last_words_emission_idx[6], rhymed_words_emission_idx[6]])\n",
    "last_words_seeds = [inverse_words_dict[idx] for idx in last_words_seeds_idx]\n",
    "print(\"---\")\n",
    "print(\"\\n\".join(last_words_seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art my to that fame for new if graces,\n",
      "Confine december's up know forth I art,\n",
      "Thou spirit some every hideous faces,\n",
      "Not I thy of find and for not depart,\n",
      "So stand false picture's the by departest,\n",
      "Use hath world your that for show kind with call,\n",
      "World I in those woman's are convertest,\n",
      "My riot me up love betwixt shun fall,\n",
      "Precious that having word brave show you spite,\n",
      "Far from your thine of thine is sweet thou lie,\n",
      "All art that then when within therefore might,\n",
      "Clay with correct dear of when hours I,\n",
      "They sweet should things things argument fair stand,\n",
      "Thy lies o'ersways make you him like mind hand.\n"
     ]
    }
   ],
   "source": [
    "# Actually make a sonnet now. Take the 14 seeds from before, construct the lines backwards, and check for syllable count.\n",
    "# If it cannot fit the right syllable count, we regenerate the line.\n",
    "\n",
    "sonnet = []\n",
    "# Iterate over each of the 14 seeds for each line\n",
    "for seed_idx in last_words_seeds_idx:\n",
    "    exactly_10_syllables = False\n",
    "    \n",
    "    while not exactly_10_syllables:\n",
    "        # Generate the line using the seed\n",
    "        line = list(reversed_line_HMM.generate_emission(10, seed=seed_idx)[0])\n",
    "        # Reverse the line\n",
    "        line = line[::-1]\n",
    "        # Add the seed at the back of the line and convert back to words\n",
    "        line.append(seed_idx)\n",
    "        line = [inverse_words_dict[word] for word in line]\n",
    "        \n",
    "        # Start from the back of the line and start adding syllables. Initially we have an empty set because we will initialise\n",
    "        # it when we read the last word. Use sets to prevent duplicates.\n",
    "        syllable_count = set([])\n",
    "        # Count backward from the last word in the line until 0\n",
    "        for i in range(len(line)-1, -1, -1):\n",
    "            \n",
    "            # Only for the last word, we also add possible end-of-line syllable counts\n",
    "            # It is empty so we initialise it by adding elements \n",
    "            if i == len(line)-1:\n",
    "                # First initialise all the normal syllables\n",
    "                syllable_count = set(syllables_dict[line[i]])\n",
    "                # Then add all the end syllables\n",
    "                syllable_count.update(end_syllables_dict[line[i]])\n",
    "\n",
    "            # For words that are not the last, we need to iterate over the new possible readings + previous possible counts\n",
    "            else:\n",
    "                # Since each word can have >1 possible syllables, we need to iterate over all past counts and\n",
    "                # all possible syllable counts of the new word. Use sets to prevent duplicates.\n",
    "                syllable_count = {count+syl for count in syllable_count for syl in syllables_dict[line[i]]}\n",
    "                # If at any point we hit 10 we are done. We chop off the line starting from when we reached 10.\n",
    "                if 10 in syllable_count:\n",
    "                    line = line[i:]\n",
    "                    exactly_10_syllables = True\n",
    "                    break\n",
    "    # Once we are out of that while loop, we have exactly 10 syllables        \n",
    "    sonnet.append(line)\n",
    "\n",
    "# Print the sonnet itself\n",
    "for idx, line in enumerate(sonnet):\n",
    "    # Upper case \"I\" and \"O\"\n",
    "    line = [word.upper() if word in (\"i\", \"o\") else word for word in line]\n",
    "    # Upper case the 1st word of each line\n",
    "    line[0] = line[0][0].upper() + line[0][1:]\n",
    "    \n",
    "    # Add comma to each line except the last\n",
    "    if idx == len(sonnet)-1:\n",
    "        line[-1] += \".\"\n",
    "    else:\n",
    "        line[-1] += \",\"\n",
    "    print(\" \".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
